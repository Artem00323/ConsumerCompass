{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fFZsTMlJIgaA",
        "outputId": "685919cb-200d-4f90-c929-383949b1b38a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# prompt: mount google drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gF4fUE4IIjUj"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "poaJAlQdW-m_"
      },
      "source": [
        "# Images from Flickr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qi4cjc3D6WRA"
      },
      "outputs": [],
      "source": [
        "# def save_images_from_flickr(api_key, query, num_images, dataset_directory):\n",
        "#     if not os.path.exists(dataset_directory):\n",
        "#         os.makedirs(dataset_directory)\n",
        "#         print(f\"Created directory: {dataset_directory}\")\n",
        "\n",
        "#     url = \"https://api.flickr.com/services/rest/\"\n",
        "#     params = {\n",
        "#         \"method\": \"flickr.photos.search\",\n",
        "#         \"api_key\": api_key,\n",
        "#         \"text\": query,\n",
        "#         \"format\": \"json\",\n",
        "#         \"nojsoncallback\": 1,\n",
        "#         \"per_page\": num_images\n",
        "#     }\n",
        "\n",
        "#     response = requests.get(url, params=params)\n",
        "#     response.raise_for_status()\n",
        "\n",
        "#     photos = response.json()[\"photos\"][\"photo\"]\n",
        "#     print(\"Photos found:\", len(photos))\n",
        "\n",
        "#     for i, photo in enumerate(photos):\n",
        "#         photo_url = f\"https://live.staticflickr.com/{photo['server']}/{photo['id']}_ {photo['secret']}.jpg\"\n",
        "#         print(\"Downloading:\", photo_url)\n",
        "\n",
        "#         img_response = requests.get(photo_url)\n",
        "#         img_response.raise_for_status()\n",
        "\n",
        "#         with open(os.path.join(dataset_directory, f\"image_{i}.jpg\"), \"wb\") as file:\n",
        "#             file.write(img_response.content)\n",
        "#             print(f\"Saved image_{i}.jpg\")\n",
        "\n",
        "\n",
        "# queries = [\"healthy\", \"unhealthy\", \"glamorous\", \"drab\",\n",
        "#            \"rugged\", \"gentle\", \"fun\", \"dull\"]\n",
        "\n",
        "# api_key = \"6c5f4e8afdb73883214c9b9471629b81\"\n",
        "\n",
        "# num_images = 200\n",
        "\n",
        "# for query in queries:\n",
        "#     dataset_directory = \"/content/\" + query\n",
        "#     save_images_from_flickr(api_key, query, num_images, dataset_directory)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I4ks0_ggWynj"
      },
      "source": [
        "## Preprocess"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XFThcZnEWxQ2"
      },
      "outputs": [],
      "source": [
        "def preprocess_image(img_path, target_size=(224, 224)):\n",
        "\n",
        "    img = cv2.imread(img_path)\n",
        "    img = cv2.resize(img, target_size)\n",
        "    img = img.astype('float32') / 255.0\n",
        "    return img\n",
        "\n",
        "# def preprocess_images_from_folders(folders, target_size=(224, 224)):\n",
        "#     preprocessed_images = {}\n",
        "\n",
        "#     for folder in folders:\n",
        "#         label = os.path.basename(folder)\n",
        "#         preprocessed_images[label] = []\n",
        "\n",
        "#         for img_file in os.listdir(folder):\n",
        "#             img_path = os.path.join(folder, img_file)\n",
        "#             if os.path.isfile(img_path):\n",
        "#                 preprocessed_images[label].append(preprocess_image(img_path, target_size))\n",
        "\n",
        "#     return preprocessed_images\n",
        "\n",
        "# folders = ['/content/healthy', '/content/unhealthy', '/content/glamorous',\n",
        "#            '/content/drab', '/content/rugged', '/content/gentle',\n",
        "#            '/content/fun', '/content/dull']\n",
        "\n",
        "# preprocessed_images = preprocess_images_from_folders(folders)\n",
        "\n",
        "# for label, images in preprocessed_images.items():\n",
        "#     print(f\"Label: {label}, Number of Images: {len(images)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qZ8CpeVvW0E6"
      },
      "source": [
        "## Save to google drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YFbK6w9SW2xv"
      },
      "outputs": [],
      "source": [
        "# def save_preprocessed_images(preprocessed_images, target_directory):\n",
        "#     if not os.path.exists(target_directory):\n",
        "#         os.makedirs(target_directory)\n",
        "\n",
        "#     for label, images in preprocessed_images.items():\n",
        "#         label_dir = os.path.join(target_directory, label)\n",
        "#         if not os.path.exists(label_dir):\n",
        "#             os.makedirs(label_dir)\n",
        "\n",
        "#         for i, img in enumerate(images):\n",
        "#             img_path = os.path.join(label_dir, f\"{label}_{i}.jpg\")\n",
        "#             cv2.imwrite(img_path, img * 255)  # Rescale back to 0-255 range\n",
        "\n",
        "# # Shared Google Drive folder path\n",
        "# shared_folder_path = '/content/drive/My Drive/ConsumerCompass/data'  # Update with the actual path\n",
        "\n",
        "# # Save images to the shared folder\n",
        "# save_preprocessed_images(preprocessed_images, shared_folder_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "joRn9fnFXDYP"
      },
      "source": [
        "## Splitting for training model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qchjj6Q_Paw7",
        "outputId": "cae6d736-f2a3-459d-d384-31504a31dc53"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/ConsumerCompass/data/healthy\n",
            "/content/drive/My Drive/ConsumerCompass/data/unhealthy\n",
            "/content/drive/My Drive/ConsumerCompass/data/glamorous\n",
            "/content/drive/My Drive/ConsumerCompass/data/drab\n",
            "/content/drive/My Drive/ConsumerCompass/data/rugged\n",
            "/content/drive/My Drive/ConsumerCompass/data/gentle\n",
            "/content/drive/My Drive/ConsumerCompass/data/fun\n",
            "/content/drive/My Drive/ConsumerCompass/data/dull\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from google.colab import drive\n",
        "\n",
        "# Google Drive folder path\n",
        "base_folder = '/content/drive/My Drive/ConsumerCompass/data'\n",
        "\n",
        "# Update folder paths\n",
        "folders = [os.path.join(base_folder, folder_name) for folder_name in ['healthy', 'unhealthy', 'glamorous', 'drab', 'rugged', 'gentle', 'fun', 'dull']]\n",
        "\n",
        "# Rest of your code for processing\n",
        "label_map = {'healthy': 0, 'unhealthy': 1, 'glamorous': 2, 'drab': 3, 'rugged': 4, 'gentle': 5, 'fun': 6, 'dull': 7}\n",
        "all_images = []\n",
        "all_labels = []\n",
        "\n",
        "for folder in folders:\n",
        "    label_index = label_map[os.path.basename(folder)]\n",
        "    print(folder)\n",
        "    for img_file in os.listdir(folder):\n",
        "        img_path = os.path.join(folder, img_file)\n",
        "        if os.path.isfile(img_path):\n",
        "            img = preprocess_image(img_path)\n",
        "            label_vector = [0] * 8\n",
        "            label_vector[label_index] = 1\n",
        "            all_images.append(img)\n",
        "            all_labels.append(label_vector)\n",
        "\n",
        "all_images = np.array(all_images)\n",
        "all_labels = np.array(all_labels)\n",
        "\n",
        "train_images, test_images, train_labels, test_labels = train_test_split(all_images, all_labels, test_size=0.3)\n",
        "val_images, test_images, val_labels, test_labels = train_test_split(test_images, test_labels, test_size=0.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_qOgDrkn9ilA"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "label_map = {'healthy': 0, 'unhealthy': 1, 'glamorous': 2, 'drab': 3,\n",
        "             'rugged': 4, 'gentle': 5, 'fun': 6, 'dull': 7}\n",
        "all_images = []\n",
        "all_labels = []\n",
        "\n",
        "for folder in folders:\n",
        "    label_index = label_map[os.path.basename(folder)]\n",
        "    for img_file in os.listdir(folder):\n",
        "        img_path = os.path.join(folder, img_file)\n",
        "        if os.path.isfile(img_path):\n",
        "            img = preprocess_image(img_path)\n",
        "            label_vector = [0] * 8\n",
        "            label_vector[label_index] = 1\n",
        "            all_images.append(img)\n",
        "            all_labels.append(label_vector)\n",
        "\n",
        "all_images = np.array(all_images)\n",
        "all_labels = np.array(all_labels)\n",
        "\n",
        "train_images, test_images, train_labels, test_labels = train_test_split(all_images, all_labels, test_size=0.3)\n",
        "val_images, test_images, val_labels, test_labels = train_test_split(test_images, test_labels, test_size=0.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5iYmuVrTgOZ0"
      },
      "outputs": [],
      "source": [
        "# from tensorflow.keras.models import Sequential\n",
        "# from tensorflow.keras.layers import Dense, Conv2D, Flatten, MaxPooling2D\n",
        "# from tensorflow.keras.optimizers import Adam\n",
        "# from tensorflow.keras.layers import Dropout, BatchNormalization\n",
        "\n",
        "# # model = Sequential([\n",
        "# #     Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),\n",
        "# #     MaxPooling2D(pool_size=(2, 2)),\n",
        "# #     Flatten(),\n",
        "# #     Dense(128, activation='relu'),\n",
        "# #     Dense(8, activation='sigmoid')\n",
        "# # ])\n",
        "\n",
        "# model = Sequential([\n",
        "#     Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),\n",
        "#     MaxPooling2D(pool_size=(2, 2)),\n",
        "#     BatchNormalization(),\n",
        "\n",
        "#     Conv2D(64, (3, 3), activation='relu'),\n",
        "#     MaxPooling2D(pool_size=(2, 2)),\n",
        "#     BatchNormalization(),\n",
        "\n",
        "#     Conv2D(128, (3, 3), activation='relu'),\n",
        "#     MaxPooling2D(pool_size=(2, 2)),\n",
        "#     BatchNormalization(),\n",
        "\n",
        "#     Flatten(),\n",
        "#     Dense(256, activation='relu'),\n",
        "#     Dropout(0.5),\n",
        "#     Dense(128, activation='relu'),\n",
        "#     Dropout(0.5),\n",
        "#     Dense(8, activation='sigmoid')\n",
        "# ])\n",
        "\n",
        "# model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "# model.fit(train_images, train_labels, validation_data=(val_images, val_labels), epochs=10)\n",
        "\n",
        "# test_loss, test_accuracy = model.evaluate(test_images, test_labels)\n",
        "# model.save('/content/model2')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PGWwDnxInTQt"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
        "\n",
        "model = Sequential([\n",
        "    # # Conv0\n",
        "    # Conv2D(filters=64, kernel_size=(15, 15), strides=(4, 4), activation='relu', input_shape=(224, 224, 3)),\n",
        "    # # MaxPool1\n",
        "    # MaxPooling2D(pool_size=(3, 3), strides=(2, 2)),\n",
        "    # # Norm1\n",
        "    # BatchNormalization(),\n",
        "\n",
        "    # Conv1\n",
        "    Conv2D(filters=96, kernel_size=(11, 11), strides=(4, 4), activation='relu', input_shape=(224, 224, 3)),\n",
        "    # MaxPool1\n",
        "    MaxPooling2D(pool_size=(3, 3), strides=(2, 2)),\n",
        "    # Norm1\n",
        "    BatchNormalization(),\n",
        "\n",
        "    # Conv2\n",
        "    Conv2D(filters=256, kernel_size=(5, 5), padding='same', activation='relu'),\n",
        "    # MaxPool2\n",
        "    MaxPooling2D(pool_size=(3, 3), strides=(2, 2)),\n",
        "    # Norm2\n",
        "    BatchNormalization(),\n",
        "\n",
        "    # Conv3\n",
        "    Conv2D(filters=384, kernel_size=(3, 3), padding='same', activation='relu'),\n",
        "\n",
        "    # Conv4\n",
        "    Conv2D(filters=384, kernel_size=(3, 3), padding='same', activation='relu'),\n",
        "\n",
        "    # Conv5\n",
        "    Conv2D(filters=256, kernel_size=(3, 3), padding='same', activation='relu'),\n",
        "    # MaxPool5\n",
        "    MaxPooling2D(pool_size=(3, 3), strides=(2, 2)),\n",
        "\n",
        "    Flatten(),\n",
        "\n",
        "    # FC6\n",
        "    Dense(4096, activation='relu'),\n",
        "    # Dropout FC6\n",
        "    Dropout(0.5),\n",
        "\n",
        "    # FC7\n",
        "    Dense(4096, activation='relu'),\n",
        "    # Dropout FC7\n",
        "    Dropout(0.5),\n",
        "\n",
        "    # FC8\n",
        "    Dense(8, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "history = model.fit(\n",
        "    train_images,\n",
        "    train_labels,\n",
        "    validation_data=(val_images, val_labels),\n",
        "    epochs=10\n",
        ")\n",
        "\n",
        "test_loss, test_accuracy = model.evaluate(test_images, test_labels)\n",
        "\n",
        "model.save('/content/model_multilabel_brandimagenet')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import tensorflow as tf\n",
        "# from tensorflow.keras.models import Sequential\n",
        "# from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
        "\n",
        "# model = Sequential([\n",
        "#     Conv2D(filters=96, kernel_size=(11, 11), strides=(4, 4), activation='relu', input_shape=(224, 224, 3)),\n",
        "#     MaxPooling2D(pool_size=(3, 3), strides=(2, 2)),\n",
        "#     BatchNormalization(),\n",
        "\n",
        "#     Conv2D(filters=256, kernel_size=(5, 5), padding='same', activation='relu'),\n",
        "#     MaxPooling2D(pool_size=(3, 3), strides=(2, 2)),\n",
        "#     BatchNormalization(),\n",
        "\n",
        "#     Conv2D(filters=384, kernel_size=(3, 3), padding='same', activation='relu'),\n",
        "#     Conv2D(filters=384, kernel_size=(3, 3), padding='same', activation='relu'),\n",
        "#     Conv2D(filters=384, kernel_size=(3, 3), padding='same', activation='relu'),\n",
        "#     Conv2D(filters=256, kernel_size=(3, 3), padding='same', activation='relu'),\n",
        "#     MaxPooling2D(pool_size=(3, 3), strides=(2, 2)),\n",
        "\n",
        "#     Flatten(),\n",
        "\n",
        "#     Dense(4096, activation='relu'),\n",
        "#     Dropout(0.5),\n",
        "#     Dense(4096, activation='relu'),\n",
        "#     Dropout(0.5),\n",
        "#     Dense(8, activation='sigmoid')\n",
        "# ])\n",
        "\n",
        "# model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "# model.summary()\n",
        "\n",
        "# history = model.fit(\n",
        "#     train_images,\n",
        "#     train_labels,\n",
        "#     validation_data=(val_images, val_labels),\n",
        "#     epochs=15\n",
        "# )\n",
        "\n",
        "# test_loss, test_accuracy = model.evaluate(test_images, test_labels)\n",
        "# model.save('/content/model_multilabel_brandimagenet')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "i7K5WYJEIdLT",
        "outputId": "25996f51-1bcd-40cd-cd30-37f530966b46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_12 (Conv2D)          (None, 54, 54, 96)        34944     \n",
            "                                                                 \n",
            " max_pooling2d_6 (MaxPoolin  (None, 26, 26, 96)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_4 (Bat  (None, 26, 26, 96)        384       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_13 (Conv2D)          (None, 26, 26, 256)       614656    \n",
            "                                                                 \n",
            " max_pooling2d_7 (MaxPoolin  (None, 12, 12, 256)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_5 (Bat  (None, 12, 12, 256)       1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_14 (Conv2D)          (None, 12, 12, 384)       885120    \n",
            "                                                                 \n",
            " conv2d_15 (Conv2D)          (None, 12, 12, 384)       1327488   \n",
            "                                                                 \n",
            " conv2d_16 (Conv2D)          (None, 12, 12, 384)       1327488   \n",
            "                                                                 \n",
            " conv2d_17 (Conv2D)          (None, 12, 12, 256)       884992    \n",
            "                                                                 \n",
            " max_pooling2d_8 (MaxPoolin  (None, 5, 5, 256)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 6400)              0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 4096)              26218496  \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 4096)              0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 4096)              16781312  \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 4096)              0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 8)                 32776     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 48108680 (183.52 MB)\n",
            "Trainable params: 48107976 (183.52 MB)\n",
            "Non-trainable params: 704 (2.75 KB)\n",
            "_________________________________________________________________\n",
            "Epoch 1/15\n",
            "12/35 [=========>....................] - ETA: 2:17 - loss: 1.4877 - accuracy: 0.1302"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-5dbe1201b046>\u001b[0m in \u001b[0;36m<cell line: 32>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m history = model.fit(\n\u001b[0m\u001b[1;32m     33\u001b[0m     \u001b[0mtrain_images\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1805\u001b[0m                         ):\n\u001b[1;32m   1806\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1807\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1808\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1809\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 832\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    866\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 868\u001b[0;31m       return tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    869\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1321\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1322\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1485\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1486\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1487\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1488\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import tensorflow as tf\n",
        "# from tensorflow.keras.models import Sequential\n",
        "# from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
        "\n",
        "# model = Sequential([\n",
        "#     # # Conv0\n",
        "#     # Conv2D(filters=64, kernel_size=(15, 15), strides=(4, 4), activation='relu', input_shape=(224, 224, 3)),\n",
        "#     # # MaxPool1\n",
        "#     # MaxPooling2D(pool_size=(3, 3), strides=(2, 2)),\n",
        "#     # # Norm1\n",
        "#     # BatchNormalization(),\n",
        "\n",
        "#     # Conv1\n",
        "#     Conv2D(filters=96, kernel_size=(11, 11), strides=(4, 4), activation='relu', input_shape=(224, 224, 3)),\n",
        "#     # MaxPool1\n",
        "#     MaxPooling2D(pool_size=(3, 3), strides=(2, 2)),\n",
        "#     # Norm1\n",
        "#     BatchNormalization(),\n",
        "\n",
        "#     # Conv2\n",
        "#     Conv2D(filters=256, kernel_size=(5, 5), padding='same', activation='relu'),\n",
        "#     # MaxPool2\n",
        "#     MaxPooling2D(pool_size=(3, 3), strides=(2, 2)),\n",
        "#     # Norm2\n",
        "#     BatchNormalization(),\n",
        "\n",
        "#     # Conv3\n",
        "#     Conv2D(filters=384, kernel_size=(3, 3), padding='same', activation='relu'),\n",
        "\n",
        "#     # Conv4\n",
        "#     Conv2D(filters=384, kernel_size=(3, 3), padding='same', activation='relu'),\n",
        "\n",
        "#     # Conv4.2\n",
        "#     Conv2D(filters=384, kernel_size=(3, 3), padding='same', activation='relu'),\n",
        "\n",
        "#     # Conv5\n",
        "#     Conv2D(filters=256, kernel_size=(3, 3), padding='same', activation='relu'),\n",
        "#     # MaxPool5\n",
        "#     MaxPooling2D(pool_size=(3, 3), strides=(2, 2)),\n",
        "\n",
        "#     Flatten(),\n",
        "\n",
        "#     # FC6\n",
        "#     Dense(4096, activation='relu'),\n",
        "#     # Dropout FC6\n",
        "#     Dropout(0.5),\n",
        "\n",
        "#     # FC7\n",
        "#     Dense(4096, activation='relu'),\n",
        "#     # Dropout FC7\n",
        "#     Dropout(0.5),\n",
        "\n",
        "#     # FC8\n",
        "#     Dense(8, activation='sigmoid')\n",
        "# ])\n",
        "\n",
        "# model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# model.summary()\n",
        "\n",
        "# history = model.fit(\n",
        "#     train_images,\n",
        "#     train_labels,\n",
        "#     validation_data=(val_images, val_labels),\n",
        "#     epochs=15\n",
        "# )\n",
        "\n",
        "# test_loss, test_accuracy = model.evaluate(test_images, test_labels)\n",
        "\n",
        "# model.save('/content/model_multilabel_brandimagenet')"
      ],
      "metadata": {
        "id": "1tHOXju98-Q5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.metrics import BinaryAccuracy\n",
        "\n",
        "predictions = model.predict(test_images)\n",
        "\n",
        "accuracy_metrics = []\n",
        "for i in range(0, predictions.shape[1], 2):\n",
        "    metric = BinaryAccuracy()\n",
        "    metric.update_state(test_labels[:, i:i+2], predictions[:, i:i+2])\n",
        "    accuracy_metrics.append(metric.result().numpy())\n",
        "\n",
        "class_pairs = ['healthy-unhealthy', 'glamorous-drab', 'rugged-gentle', 'fun-dull']\n",
        "for i, acc in enumerate(accuracy_metrics):\n",
        "    print(f\"Accuracy for {class_pairs[i]}: {acc}\")\n",
        "\n",
        "# 8/8 [==============================] - 11s 1s/step\n",
        "# Accuracy for healthy-unhealthy: 0.8640167117118835\n",
        "# Accuracy for glamorous-drab: 0.9163179993629456\n",
        "# Accuracy for rugged-gentle: 0.8870292901992798\n",
        "# Accuracy for fun-dull: 0.8891213536262512"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WLimpWQu5OWj",
        "outputId": "26ac697a-00c5-4afb-f06d-cf5d2867393f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8/8 [==============================] - 10s 1s/step\n",
            "Accuracy for healthy-unhealthy: 0.8682008385658264\n",
            "Accuracy for glamorous-drab: 0.8598326444625854\n",
            "Accuracy for rugged-gentle: 0.8619247078895569\n",
            "Accuracy for fun-dull: 0.910041868686676\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JEY39B1AjH1a"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "model = load_model('/content/model2')\n",
        "\n",
        "image_path = '/content/test/pic1.jpg' # upload to google collab manually\n",
        "\n",
        "img = preprocess_image(image_path)\n",
        "\n",
        "img_batch = np.expand_dims(img, axis=0)\n",
        "\n",
        "predictions = model.predict(img_batch)\n",
        "\n",
        "final_classification = []\n",
        "\n",
        "for i in range(0, len(predictions[0]), 2):\n",
        "    if predictions[0][i] > predictions[0][i+1]:\n",
        "        final_classification.extend([1, 0])\n",
        "    else:\n",
        "        final_classification.extend([0, 1])\n",
        "\n",
        "print(final_classification)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ts1d1Q6Q-Sue"
      },
      "outputs": [],
      "source": [
        "queries = [\"healthy\", \"unhealthy\", \"glamorous\", \"drab\",\n",
        "           \"rugged\", \"gentle\", \"fun\", \"dull\"]\n",
        "\n",
        "def normalize_and_print_predictions(predictions):\n",
        "    normalized_predictions = []\n",
        "\n",
        "    for i in range(0, len(predictions[0]), 2):\n",
        "        pair_sum = predictions[0][i] + predictions[0][i+1]\n",
        "        normalized_pair = [predictions[0][i] / pair_sum, predictions[0][i+1] / pair_sum]\n",
        "        normalized_predictions.extend(normalized_pair)\n",
        "\n",
        "    # Print the normalized predictions\n",
        "    for i in range(0, len(normalized_predictions), 2):\n",
        "        print(f\"{queries[i]}: [{normalized_predictions[i]:.2f}, {normalized_predictions[i+1]:.2f}]\")\n",
        "\n",
        "normalize_and_print_predictions(predictions)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nGpPNOuPtTpA"
      },
      "outputs": [],
      "source": [
        "# [0, 1, 0, 1, 1, 0, 0, 1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KmFJ1KP8XZ3_"
      },
      "outputs": [],
      "source": [
        "# healthy: [0.52, 0.48]\n",
        "# glamorous: [0.11, 0.89]\n",
        "# rugged: [0.34, 0.66]\n",
        "# fun: [0.58, 0.42]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h__U8UHVEAjk"
      },
      "outputs": [],
      "source": [
        "# healthy: [0.35, 0.65]\n",
        "# glamorous: [0.81, 0.19]\n",
        "# rugged: [0.00, 1.00]\n",
        "# fun: [0.01, 0.99]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h9WiIvjV5Dk9"
      },
      "outputs": [],
      "source": [
        "# 0 at index 0 (healthy): The model predicts that the image is not 'healthy'.\n",
        "# 1 at index 1 (unhealthy): The model predicts that the image is 'unhealthy'.\n",
        "# 0 at index 2 (glamorous): The model predicts that the image is not 'glamorous'.\n",
        "# 0 at index 3 (drab): The model predicts that the image is not 'drab'.\n",
        "# 1 at index 4 (rugged): The model predicts that the image is 'rugged'.\n",
        "# 0 at index 5 (gentle): The model predicts that the image is not 'gentle'.\n",
        "# 1 at index 6 (fun): The model predicts that the image is 'fun'.\n",
        "# 0 at index 7 (dull): The model predicts that the image is not 'dull'."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "qZ8CpeVvW0E6"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}