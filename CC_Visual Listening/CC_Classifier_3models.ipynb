{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GP5QK322rY0r"
   },
   "outputs": [],
   "source": [
    "# !pip install torch torchvision\n",
    "# !pip install yolov5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s7FeSVhUruTy",
    "outputId": "33fcdbb6-ac1a-4f1d-8fe8-26d02aa4d928"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive', force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5iZF05THmi6N"
   },
   "source": [
    "# Splitting for training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CMUaf_STl9nM",
    "outputId": "73b516d8-8e0a-47c1-95a4-27a77564cf71"
   },
   "outputs": [],
   "source": [
    "def preprocess_image(img_path, target_size=(224, 224)):  # size should fit yolov5 input\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.resize(img, target_size)\n",
    "    #img = img.astype('float32') / 255.0  # normalozation # dont work with yolov5\n",
    "    return img\n",
    "\n",
    "\n",
    "# Google drive (if colab)\n",
    "# base_folder = '/content/drive/My Drive/ConsumerCompass/data'\n",
    "\n",
    "base_folder = 'data 2' #insert your path\n",
    "\n",
    "folders = [os.path.join(base_folder, folder_name) for folder_name in ['healthy', 'unhealthy', 'glamorous', 'drab', 'rugged', 'gentle', 'fun', 'dull',\n",
    "                                                                      'innovation', 'conservatism', 'premuim', 'accessibility', 'minimalism', 'detail', 'safety', 'risk']]\n",
    "#class lables \n",
    "label_map = {'healthy': 0, 'unhealthy': 1, 'glamorous': 2, 'drab': 3, 'rugged': 4, 'gentle': 5, 'fun': 6, 'dull': 7,\n",
    "             'innovation': 8, 'conservatism': 9, 'premuim': 10, 'accessibility': 11, 'minimalism': 12, 'detail': 13, 'safety': 14, 'risk': 15}\n",
    "\n",
    "all_images = []\n",
    "all_labels = []\n",
    "\n",
    "# Dataframe creation \n",
    "for folder in folders:\n",
    "    label_index = label_map[os.path.basename(folder)]\n",
    "    print(folder)\n",
    "    for img_file in os.listdir(folder):\n",
    "        img_path = os.path.join(folder, img_file)\n",
    "        if os.path.isfile(img_path):\n",
    "            img = preprocess_image(img_path)\n",
    "            label_vector = [0] * 16 # number of lables\n",
    "            label_vector[label_index] = 1\n",
    "            all_images.append(img)\n",
    "            all_labels.append(label_vector)\n",
    "\n",
    "all_images = np.array(all_images)\n",
    "all_labels = np.array(all_labels)\n",
    "\n",
    "train_images, test_images, train_labels, test_labels = train_test_split(all_images, all_labels, test_size=0.3, random_state=42)\n",
    "val_images, test_images, val_labels, test_labels = train_test_split(test_images, test_labels, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def preprocess_image(img_path, target_size=(224, 224)):\n",
    "#     img = cv2.imread(img_path)\n",
    "#     if img is None:\n",
    "#         print(f\"Failed to load image at {img_path}\")\n",
    "#         return None\n",
    "#     img = cv2.resize(img, target_size)\n",
    "#     return img\n",
    "\n",
    "# def load_and_preprocess_images(image_folder):\n",
    "#     processed_images = []\n",
    "#     image_names = []  # Список для сохранения имен файлов\n",
    "#     image_files = os.listdir(image_folder)\n",
    "    \n",
    "#     for img_file in image_files:\n",
    "#         img_path = os.path.join(image_folder, img_file)\n",
    "#         if os.path.isfile(img_path):\n",
    "#             print(f\"Processing image: {img_file}\")  # Вывод названия файла перед обработкой\n",
    "#             img = preprocess_image(img_path)\n",
    "#             if img is not None:\n",
    "#                 processed_images.append(img)\n",
    "#                 image_names.append(img_file)  # Сохранение имени файла\n",
    "#             else:\n",
    "#                 print(f\"Skipping file: {img_path}\")  # Сообщение о пропуске файла\n",
    "\n",
    "#     return np.array(processed_images), image_names\n",
    "\n",
    "# data_3_folder = '/Users/andrewshatalov/Downloads/Telegram Desktop/data 3'\n",
    "# df_real, image_names = load_and_preprocess_images(data_3_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "trMqOEp-3PCn",
    "outputId": "7815f193-ea2f-484f-82e2-4f5672ac5c09"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Lambda, Dense, Dropout, Flatten, Concatenate, Conv2D, MaxPooling2D, BatchNormalization\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.models import Sequential\n",
    "import torch\n",
    "\n",
    "#download yolo pretrained model\n",
    "#if this dont work try to download from yolo githab direct link \n",
    "model_yolo = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "#function fot yolo object detection\n",
    "def detect_objects_yolo(images, model):\n",
    "    results = []\n",
    "    # transfer each image to the model\n",
    "    for img in images:\n",
    "        result = model(img)\n",
    "        results.append(result)\n",
    "    return results\n",
    "\n",
    "#detection of train test and val datasets\n",
    "train_results = detect_objects_yolo(train_images, model_yolo)\n",
    "test_results = detect_objects_yolo(test_images, model_yolo)\n",
    "val_results = detect_objects_yolo(val_images, model_yolo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_real_results = detect_objects_yolo(df_real, model_yolo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Image\n",
    "import io\n",
    "\n",
    "def display_detection_results(images, results, num):\n",
    "    # We process the first n images and the results\n",
    "    for img, result in zip(images[:num], results[:num]):\n",
    "        # get an image with superimposed frames\n",
    "        result_img = result.render()[0]\n",
    "\n",
    "        # converting the image to JPEG format for display in Jupyter\n",
    "        is_success, buffer = cv2.imencode(\".jpg\", result_img)\n",
    "        if not is_success:\n",
    "            raise ValueError(\"Failed to encode image\")\n",
    "        \n",
    "        # creating an Image object and displaying it\n",
    "        io_buf = io.BytesIO(buffer)\n",
    "        display(Image(data=io_buf.getvalue()))\n",
    "\n",
    "display_detection_results(train_images, train_results, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for creadtion a dataframe prepared for model input\n",
    "def prepare_model_inputs(images, results, image_size=(224, 224), max_objects=10):\n",
    "    prepared_images = []\n",
    "    object_infos = []\n",
    "\n",
    "    for img, detection in zip(images, results):\n",
    "        img_resized = cv2.resize(img, image_size)\n",
    "        prepared_images.append(img_resized)\n",
    "\n",
    "        # extract coordinates and classes, check if there are detections\n",
    "        if detection.xyxy[0].shape[0] > 0:\n",
    "            objects_info = detection.xyxy[0][:max_objects, :5].cpu().numpy()  \n",
    "        else:\n",
    "            objects_info = np.zeros((max_objects, 5))  # if there are no detections, creating an empty array\n",
    "\n",
    "        # coordinate normalization for each detection\n",
    "        if objects_info.shape[0] > 0:\n",
    "            objects_info[:, [0, 2]] /= img.shape[1]\n",
    "            objects_info[:, [1, 3]] /= img.shape[0]\n",
    "\n",
    "        if objects_info.shape[0] < max_objects:\n",
    "            padding = np.zeros((max_objects - objects_info.shape[0], 5))\n",
    "            objects_info = np.vstack([objects_info, padding])\n",
    "\n",
    "        object_infos.append(objects_info)\n",
    "\n",
    "    prepared_images = np.array(prepared_images, dtype=np.float32)\n",
    "    object_infos = np.array(object_infos, dtype=np.float32)\n",
    "\n",
    "    return prepared_images, object_infos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images_prepared, train_object_infos = prepare_model_inputs(train_images, train_results)\n",
    "test_images_prepared, test_object_infos = prepare_model_inputs(test_images, test_results)\n",
    "val_images_prepared, val_object_infos = prepare_model_inputs(val_images, val_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_real_prepared, df_real_infos = prepare_model_inputs(df_real, df_real_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EAHIQgas6WlL"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, Flatten, Concatenate, Conv2D, MaxPooling2D, BatchNormalization\n",
    "from tensorflow.keras.layers import GlobalAveragePooling1D\n",
    "\n",
    "# Define the base model\n",
    "base_model = Sequential([\n",
    "    Conv2D(96, (11, 11), strides=(4, 4), activation='relu', input_shape=(224, 224, 3)),\n",
    "    MaxPooling2D((3, 3), strides=(2, 2)),\n",
    "    BatchNormalization(),\n",
    "    Conv2D(256, (5, 5), padding='same', activation='relu'),\n",
    "    MaxPooling2D((3, 3), strides=(2, 2)),\n",
    "    BatchNormalization(),\n",
    "    Conv2D(384, (3, 3), padding='same', activation='relu'),\n",
    "    Conv2D(384, (3, 3), padding='same', activation='relu'),\n",
    "    Conv2D(256, (3, 3), padding='same', activation='relu'),\n",
    "    MaxPooling2D((3, 3), strides=(2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(4096, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(4096, activation='relu'),\n",
    "    Dropout(0.5)\n",
    "])\n",
    "\n",
    "# Inputs\n",
    "image_input = Input(shape=(224, 224, 3))\n",
    "object_info_input = Input(shape=(None, 5))  # Assuming this is [x_min, y_min, x_max, y_max, class_id]\n",
    "\n",
    "# Base model features\n",
    "features = base_model(image_input)\n",
    "\n",
    "# Use global pooling for the object info\n",
    "object_info_pooled = GlobalAveragePooling1D()(object_info_input)\n",
    "\n",
    "# Combine the features\n",
    "combined_features = Concatenate()([features, object_info_pooled])\n",
    "\n",
    "# Classification layers\n",
    "classification_output = Dense(4096, activation='relu')(combined_features)\n",
    "classification_output = Dropout(0.5)(classification_output)\n",
    "classification_output = Dense(4096, activation='relu')(classification_output)\n",
    "classification_output = Dropout(0.5)(classification_output)\n",
    "final_output = Dense(16, activation='sigmoid')(classification_output)\n",
    "\n",
    "# Create the model\n",
    "model1 = Model(inputs=[image_input, object_info_input], outputs=final_output)\n",
    "model1.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model1.fit(\n",
    "    [train_images, train_object_infos], train_labels,\n",
    "    validation_data=([val_images, val_object_infos], val_labels),\n",
    "    epochs=10,\n",
    "    batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.metrics import BinaryAccuracy\n",
    "\n",
    "#make predictions\n",
    "predictions = model1.predict([test_images_prepared, test_object_infos])\n",
    "\n",
    "#calculate accuracy\n",
    "accuracy_metrics = []\n",
    "for i in range(0, predictions.shape[1], 2):\n",
    "    metric = BinaryAccuracy()\n",
    "    metric.update_state(test_labels[:, i:i+2], predictions[:, i:i+2])\n",
    "    accuracy_metrics.append(metric.result().numpy())\n",
    "\n",
    "class_pairs = ['healthy-unhealthy', 'glamorous-drab', 'rugged-gentle', 'fun-dull',\n",
    "               'innovation-conservatism', 'premuim-accessibility', 'minimalism-detail', 'safety-risk']\n",
    "\n",
    "# print accuracy for every single pair \n",
    "for i, acc in enumerate(accuracy_metrics):\n",
    "    print(f\"Accuracy for {class_pairs[i]}: {acc}\")\n",
    "\n",
    "# print avg accuracy\n",
    "average_accuracy = np.mean(accuracy_metrics)\n",
    "print(f\"Average Accuracy across all class pairs: {average_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, Flatten, Concatenate, Conv2D, MaxPooling2D, BatchNormalization, GlobalAveragePooling2D, GlobalAveragePooling1D, LSTM, Bidirectional\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "object_info_input = Input(shape=(None, 5))  # Assuming this is [x_min, y_min, x_max, y_max, class_id]\n",
    "\n",
    "object_info_processed = Bidirectional(LSTM(256))(object_info_input)\n",
    "object_info_processed = Dense(512, activation='relu', kernel_regularizer=l2(0.01))(object_info_processed)\n",
    "object_info_processed = Dropout(0.5)(object_info_processed)\n",
    "\n",
    "combined_features = Concatenate()([x, object_info_processed])\n",
    "combined_features = Dense(1024, activation='relu')(combined_features)\n",
    "combined_features = Dropout(0.5)(combined_features)\n",
    "combined_features = BatchNormalization()(combined_features)\n",
    "\n",
    "final_output = Dense(16, activation='sigmoid')(combined_features)\n",
    "\n",
    "model2 = Model(inputs=[base_model.input, object_info_input], outputs=final_output)\n",
    "\n",
    "model2.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jwg1wNduaHIL"
   },
   "outputs": [],
   "source": [
    "history = model2.fit(\n",
    "    [train_images, train_object_infos], train_labels,\n",
    "    validation_data=([val_images, val_object_infos], val_labels),\n",
    "    epochs=10,\n",
    "    batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import (\n",
    "    Input, Dense, Dropout, Flatten, Concatenate, Conv2D, MaxPooling2D, BatchNormalization,\n",
    "    GlobalAveragePooling1D, Add, Activation\n",
    ")\n",
    "\n",
    "# residual block definition\n",
    "def residual_block(x, filters, kernel_size=3, stride=1, conv_shortcut=True):\n",
    "    \"\"\"A residual block with or without a convolutional shortcut.\"\"\"\n",
    "    shortcut = x\n",
    "    if conv_shortcut:\n",
    "        shortcut = Conv2D(filters, (1, 1), strides=stride)(x)\n",
    "        shortcut = BatchNormalization()(shortcut)\n",
    "\n",
    "    x = Conv2D(filters, kernel_size, strides=stride, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(filters, kernel_size, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x = Add()([shortcut, x])\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "image_input = Input(shape=(224, 224, 3))\n",
    "object_info_input = Input(shape=(None, 5))  # Assuming [x_min, y_min, x_max, y_max, class_id]\n",
    "\n",
    "# base model with residual blocks\n",
    "x = Conv2D(64, (7, 7), strides=(2, 2), padding='same', activation='relu')(image_input)\n",
    "x = MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "x = residual_block(x, 64)\n",
    "x = residual_block(x, 64)\n",
    "x = residual_block(x, 128, stride=2)\n",
    "x = residual_block(x, 128)\n",
    "\n",
    "# adding dense layers\n",
    "x = Flatten()(x)\n",
    "x = Dense(4096, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(4096, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "# use global pooling for object information\n",
    "object_info_pooled = GlobalAveragePooling1D()(object_info_input)\n",
    "\n",
    "# combine the features\n",
    "combined_features = Concatenate()([x, object_info_pooled])\n",
    "\n",
    "# classification layers\n",
    "classification_output = Dense(4096, activation='relu')(combined_features)\n",
    "classification_output = Dropout(0.5)(classification_output)\n",
    "final_output = Dense(16, activation='sigmoid')(classification_output)\n",
    "\n",
    "model3 = Model(inputs=[image_input, object_info_input], outputs=final_output)\n",
    "model3.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model3.fit(\n",
    "    [train_images, train_object_infos], train_labels,\n",
    "    validation_data=([val_images, val_object_infos], val_labels),\n",
    "    epochs=10,  # Number of training epochs\n",
    "    batch_size=32  # Batch size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_predictions = model3.predict([df_real_prepared, df_real_infos])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = [name for name, index in sorted(label_map.items(), key=lambda x: x[1])]\n",
    "predictions_df = pd.DataFrame(real_predictions, columns=column_names)\n",
    "\n",
    "for pair in class_pairs:\n",
    "    class_1, class_2 = pair.split('-')\n",
    "    greater_class = predictions_df[[class_1, class_2]].idxmax(axis=1)\n",
    "    predictions_df[class_1] = 0\n",
    "    predictions_df[class_2] = 0\n",
    "    for i, cls in enumerate(greater_class):\n",
    "        predictions_df.at[i, cls] = 1\n",
    "\n",
    "predictions_df['image_name'] = image_names \n",
    "predictions_df.rename(columns={'premuim': 'premium'}, inplace=True)\n",
    "\n",
    "print(predictions_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def determine_company(image_name):\n",
    "#     num = int(image_name.split('_')[1].split('.')[0])\n",
    "    \n",
    "#     if num == 0:\n",
    "#         return 'Nike'\n",
    "#     elif 1 <= num <= 6:\n",
    "#         return 'Netflix'\n",
    "#     elif 7 <= num <= 15:\n",
    "#         return 'Yandex_Travel'\n",
    "#     elif 16 <= num <= 35:\n",
    "#         return 'Nike'\n",
    "#     elif 36 <= num <= 78:\n",
    "#         return 'Netflix'\n",
    "#     else:\n",
    "#         return 'Unknown'\n",
    "\n",
    "# predictions_df['company_name'] = predictions_df['image_name'].apply(determine_company)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions_df.to_csv('real_predictions3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WsPor_TmmmD9"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.metrics import BinaryAccuracy\n",
    "\n",
    "#make predictions\n",
    "predictions = model3.predict([test_images_prepared, test_object_infos])\n",
    "\n",
    "#calculate accuracy\n",
    "accuracy_metrics = []\n",
    "for i in range(0, predictions.shape[1], 2):\n",
    "    metric = BinaryAccuracy()\n",
    "    metric.update_state(test_labels[:, i:i+2], predictions[:, i:i+2])\n",
    "    accuracy_metrics.append(metric.result().numpy())\n",
    "\n",
    "class_pairs = ['healthy-unhealthy', 'glamorous-drab', 'rugged-gentle', 'fun-dull',\n",
    "               'innovation-conservatism', 'premuim-accessibility', 'minimalism-detail', 'safety-risk']\n",
    "\n",
    "# print accuracy for every single pair \n",
    "for i, acc in enumerate(accuracy_metrics):\n",
    "    print(f\"Accuracy for {class_pairs[i]}: {acc}\")\n",
    "\n",
    "# print avg accuracy\n",
    "average_accuracy = np.mean(accuracy_metrics)\n",
    "print(f\"Average Accuracy across all class pairs: {average_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def calculate_tp_fp_tn_fn_per_pair(model, test_images, test_object_infos, test_labels):\n",
    "    predictions = model.predict([test_images, test_object_infos])\n",
    "    predictions_binary = (predictions > 0.5).astype(int)\n",
    "    \n",
    "    results = []\n",
    "\n",
    "    for i in range(0, test_labels.shape[1], 2):\n",
    "        # filtering images for every pair\n",
    "        relevant_indices = (test_labels[:, i] + test_labels[:, i + 1] > 0)\n",
    "        relevant_labels = test_labels[relevant_indices, i:i+2]\n",
    "        relevant_predictions = predictions_binary[relevant_indices, i:i+2]\n",
    "\n",
    "        tp_metric = tf.keras.metrics.TruePositives()\n",
    "        fp_metric = tf.keras.metrics.FalsePositives()\n",
    "        tn_metric = tf.keras.metrics.TrueNegatives()\n",
    "        fn_metric = tf.keras.metrics.FalseNegatives()\n",
    "        \n",
    "        #calculate tp fp tn fn for inside pair\n",
    "        tp_metric.update_state(relevant_labels, relevant_predictions)\n",
    "        fp_metric.update_state(relevant_labels, relevant_predictions)\n",
    "        tn_metric.update_state(relevant_labels, relevant_predictions)\n",
    "        fn_metric.update_state(relevant_labels, relevant_predictions)\n",
    "        \n",
    "        results.append({\n",
    "            'TP': tp_metric.result().numpy(),\n",
    "            'FP': fp_metric.result().numpy(),\n",
    "            'TN': tn_metric.result().numpy(),\n",
    "            'FN': fn_metric.result().numpy()\n",
    "        })\n",
    "        \n",
    "    return results\n",
    "\n",
    "results = calculate_tp_fp_tn_fn_per_pair(model3, test_images_prepared, test_object_infos, test_labels)\n",
    "\n",
    "class_pairs = ['healthy-unhealthy', 'glamorous-drab', 'rugged-gentle', 'fun-dull',\n",
    "               'innovation-conservatism', 'premuim-accessibility', 'minimalism-detail', 'safety-risk']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to calculate precision for pair\n",
    "def calculate_precision(results):\n",
    "    precisions = []\n",
    "    for result in results:\n",
    "        tp = result['TP']\n",
    "        fp = result['FP']\n",
    "        if tp + fp == 0:\n",
    "            precision = 0\n",
    "        else:\n",
    "            precision = tp / (tp + fp)\n",
    "        precisions.append(precision)\n",
    "    return precisions\n",
    "\n",
    "#calculate precision for every pair\n",
    "precisions = calculate_precision(results)\n",
    "\n",
    "class_pairs = ['healthy-unhealthy', 'glamorous-drab', 'rugged-gentle', 'fun-dull',\n",
    "               'innovation-conservatism', 'premuim-accessibility', 'minimalism-detail', 'safety-risk']\n",
    "\n",
    "#print precision for every pair\n",
    "for i, (precision, result) in enumerate(zip(precisions, results)):\n",
    "    print(f\"{class_pairs[i]}: Precision={precision:.4f}\")\n",
    "\n",
    "#calculate and print avg precision\n",
    "average_precision = np.mean(precisions)\n",
    "print(f\"Average Precision across all class pairs: {average_precision:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.save('model3.h5')  # Download model in HDF5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model ensemble "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions1 = (model1.predict([test_images_prepared, test_object_infos]) > 0.5).astype(int)\n",
    "# predictions2 = (model2.predict([test_images_prepared, test_object_infos]) > 0.5).astype(int)\n",
    "# predictions3 = (model3.predict([test_images_prepared, test_object_infos]) > 0.5).astype(int)\n",
    "\n",
    "\n",
    "# # Stack predictions along a new axis to form a matrix [n_samples, n_models]\n",
    "# predictions_stack = np.stack([predictions1, predictions2, predictions3], axis=1)\n",
    "\n",
    "# # Majority voting: Count the number of times 1 appears and decide the class based on the majority\n",
    "# majority_vote = np.apply_along_axis(lambda x: 1 if np.sum(x) >= 2 else 0, axis=1, arr=predictions_stack)\n",
    "\n",
    "# from tensorflow.keras.metrics import BinaryAccuracy\n",
    "\n",
    "# # Assume test_labels is your ground truth labels array of the same shape as predictions [n_samples, n_classes]\n",
    "# accuracy_metrics = []\n",
    "# class_pairs = ['healthy-unhealthy', 'glamorous-drab', 'rugged-gentle', 'fun-dull',\n",
    "#                'innovation-conservatism', 'premium-accessibility', 'minimalism-detail', 'safety-risk']\n",
    "\n",
    "# # Iterate over each pair (assuming each pair is composed of two classes)\n",
    "# for i in range(0, majority_vote.shape[1], 2):\n",
    "#     metric = BinaryAccuracy()\n",
    "#     metric.update_state(test_labels[:, i:i+2], majority_vote[:, i:i+2])\n",
    "#     accuracy_metrics.append(metric.result().numpy())\n",
    "\n",
    "# # Print the results for each class pair\n",
    "# for i, acc in enumerate(accuracy_metrics):\n",
    "#     print(f\"Accuracy for {class_pairs[i]}: {acc}\")\n",
    "\n",
    "# average_accuracy = np.mean(accuracy_metrics)\n",
    "# print(f\"Average Accuracy across all class pairs: {average_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
